{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 abstract  \\\n",
      "0       The purpose of this study is to develop a lear...   \n",
      "1       This paper describes the design and implementa...   \n",
      "2       This article applied GARCH model instead AR or...   \n",
      "3                                                     NaN   \n",
      "4                                                     NaN   \n",
      "...                                                   ...   \n",
      "999995                                                NaN   \n",
      "999996  In the last few years, workflow systems have b...   \n",
      "999997  There are many different designs for audio amp...   \n",
      "999998  This paper proposes a language acquisition fra...   \n",
      "999999  Abstract   This thesis investigates the mathem...   \n",
      "\n",
      "                                                  authors  n_citation  \\\n",
      "0       [Makoto Satoh, Ryo Muramatsu, Mizue Kayama, Ka...           0   \n",
      "1                             [Gareth Beale, Graeme Earl]          50   \n",
      "2       [Altaf Hossain, Faisal Zaman, Mohammed Nasser,...          50   \n",
      "3       [Jea-Bum Park, Byungmok Kim, Jian Shen, Sun-Yo...           0   \n",
      "4                     [Giovanna Guerrini, Isabella Merlo]           2   \n",
      "...                                                   ...         ...   \n",
      "999995  [Julien Stephan, Mathieu Brau, Yoann Corre, Yv...           4   \n",
      "999996                               [Giacomo Piccinelli]          10   \n",
      "999997                   [Stephen M. Cox, Bruce H. Candy]          19   \n",
      "999998     [Tao Gong, James W. Minett, William S-Y. Wang]           5   \n",
      "999999                                [Mathias Kegelmann]          22   \n",
      "\n",
      "                                               references  \\\n",
      "0       [51c7e02e-f5ed-431a-8cf5-f761f266d4be, 69b625b...   \n",
      "1       [10482dd3-4642-4193-842f-85f3b70fcf65, 3133714...   \n",
      "2       [2d84c0f2-e656-4ce7-b018-90eda1c132fe, a083a1b...   \n",
      "3       [8c78e4b0-632b-4293-b491-85b1976675e6, 9cdc54f...   \n",
      "4                                                     NaN   \n",
      "...                                                   ...   \n",
      "999995  [13706ee7-da12-440d-8b13-ab6106e77887, 16a2526...   \n",
      "999996  [02763555-4d84-49fa-b6aa-00171c832dc0, 4be4595...   \n",
      "999997             [3059f971-f49e-4a49-a1e5-82ea4e8f6879]   \n",
      "999998  [207c4e1c-52f4-4737-9cd9-1db86b33d580, 55c81e3...   \n",
      "999999  [1cddd8b1-8262-4351-9606-e1eb710f2159, 2026759...   \n",
      "\n",
      "                                                    title  \\\n",
      "0       Preliminary Design of a Network Protocol Learn...   \n",
      "1       A methodology for the physically accurate visu...   \n",
      "2       Comparison of GARCH, Neural Network and Suppor...   \n",
      "3       Development of Remote Monitoring and Control D...   \n",
      "4       Reasonig about Set-Oriented Methods in Object ...   \n",
      "...                                                   ...   \n",
      "999995  On the Effect of Realistic Traffic Demand Rise...   \n",
      "999996    Distributed workflow management: the TEAM model   \n",
      "999997    Class-D Audio Amplifiers with Negative Feedback   \n",
      "999998  A simulation study exploring the role of cultu...   \n",
      "999999                 Continuous Domains in Logical Form   \n",
      "\n",
      "                                                    venue  year  \\\n",
      "0       international conference on human-computer int...  2013   \n",
      "1                 visual analytics science and technology  2011   \n",
      "2            pattern recognition and machine intelligence  2009   \n",
      "3                                                          2011   \n",
      "4                                                          1998   \n",
      "...                                                   ...   ...   \n",
      "999995                    vehicular technology conference  2014   \n",
      "999996                    cooperative information systems  1998   \n",
      "999997                Siam Journal on Applied Mathematics  2005   \n",
      "999998                                 Connection Science  2010   \n",
      "999999   Electronic Notes in Theoretical Computer Science  2002   \n",
      "\n",
      "                                          id  \n",
      "0       00127ee2-cb05-48ce-bc49-9de556b93346  \n",
      "1       001c58d3-26ad-46b3-ab3a-c1e557d16821  \n",
      "2       001c8744-73c4-4b04-9364-22d31a10dbf1  \n",
      "3       00338203-9eb3-40c5-9f31-cbac73a519ec  \n",
      "4       0040b022-1472-4f70-a753-74832df65266  \n",
      "...                                      ...  \n",
      "999995  4aa66242-5efc-464f-8b80-463691a50e2e  \n",
      "999996  4aa672c2-c5e6-469d-b168-2056474cf47f  \n",
      "999997  4aa67ed9-6b28-4ed4-a180-13d3a0dc0a59  \n",
      "999998  4aa692aa-2448-436c-a809-81b54e5f2f66  \n",
      "999999  4aa6935e-6e0f-48fa-ad76-769805cd879d  \n",
      "\n",
      "[1000000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_json('dblp-ref-0.json', lines=True)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df.dropna(subset = [\"references\"], inplace=True)\n",
    "df.dropna(subset = [\"abstract\"], inplace=True)\n",
    "df=df[df['references'].map(lambda d: len(d)) > 0]\n",
    "df=df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             abstract  \\\n",
      "0   The purpose of this study is to develop a lear...   \n",
      "1   This paper describes the design and implementa...   \n",
      "2   This article applied GARCH model instead AR or...   \n",
      "3   Recent achievements in Natural Language Proces...   \n",
      "4   Most applications of the abstract interpretati...   \n",
      "..                                                ...   \n",
      "95  In this paper we present an original semi-supe...   \n",
      "96  The morphological changes of the vertebrae ass...   \n",
      "97  Automated system deployment frameworks and con...   \n",
      "98  We study the role of help in Non-Interactive Z...   \n",
      "99  Multiple datasets that add high value to biome...   \n",
      "\n",
      "                                              authors  n_citation  \\\n",
      "0   [Makoto Satoh, Ryo Muramatsu, Mizue Kayama, Ka...           0   \n",
      "1                         [Gareth Beale, Graeme Earl]          50   \n",
      "2   [Altaf Hossain, Faisal Zaman, Mohammed Nasser,...          50   \n",
      "3   [Ankita Brahmachari, Priya Singh, Avdhesh Garg...           0   \n",
      "4                     [Patrick Cousot, Radhia Cousot]          50   \n",
      "..                                                ...         ...   \n",
      "95                 [Philippe Borianne, Gérard Subsol]           1   \n",
      "96  [Tristan Whitmarsh, Luis Miguel del Río Barque...           2   \n",
      "97  [Donna D. Cumberland, Randy Herban, Rick Irvin...           4   \n",
      "98              [André Chailloux, Iordanis Kerenidis]           1   \n",
      "99  [Ali Hasnain, Syeda Sana e Zainab, Maulik R. K...          16   \n",
      "\n",
      "                                           references  \\\n",
      "0   [51c7e02e-f5ed-431a-8cf5-f761f266d4be, 69b625b...   \n",
      "1   [10482dd3-4642-4193-842f-85f3b70fcf65, 3133714...   \n",
      "2   [2d84c0f2-e656-4ce7-b018-90eda1c132fe, a083a1b...   \n",
      "3   [84d47128-58d0-4187-aa44-389fde7d5c83, e0dce69...   \n",
      "4   [6e8a3ec3-9a99-4fac-ac4d-f8d1bf0fa208, 7bb71af...   \n",
      "..                                                ...   \n",
      "95  [0b274997-5bc1-44d4-b90b-7d4919ee3fee, 4d4bcdf...   \n",
      "96  [43d73924-325a-42f8-a1b6-8b616ea22b2f, 50b1abc...   \n",
      "97  [31057a8b-6377-40c4-9d27-fecb6b05e366, 39fe22d...   \n",
      "98             [0dd040aa-d2e6-447d-ad59-c2a19b828c99]   \n",
      "99  [16fbe51f-8a05-4f17-92c0-6f9e77e68dc4, 18b55f4...   \n",
      "\n",
      "                                                title  \\\n",
      "0   Preliminary Design of a Network Protocol Learn...   \n",
      "1   A methodology for the physically accurate visu...   \n",
      "2   Comparison of GARCH, Neural Network and Suppor...   \n",
      "3   Identifying Psychological Theme Words from Emo...   \n",
      "4   Relational Abstract Interpretation of Higher O...   \n",
      "..                                                ...   \n",
      "95  Fast semi-supervised segmentation of in-situ t...   \n",
      "96  Age-Related changes in vertebral morphometry b...   \n",
      "97  Rapid parallel systems deployment: techniques ...   \n",
      "98  The role of help in Classical and Quantum Zero...   \n",
      "99  A Roadmap for Navigating the Life Sciences Lin...   \n",
      "\n",
      "                                                venue  year  \\\n",
      "0   international conference on human-computer int...  2013   \n",
      "1             visual analytics science and technology  2011   \n",
      "2        pattern recognition and machine intelligence  2009   \n",
      "3                                                      2013   \n",
      "4                                                      1991   \n",
      "..                                                ...   ...   \n",
      "95  international conference on image and signal p...  2014   \n",
      "96                                                     2012   \n",
      "97  usenix large installation systems administrati...  2008   \n",
      "98                             arXiv: Quantum Physics  2007   \n",
      "99                                                     2014   \n",
      "\n",
      "                                      id  \n",
      "0   00127ee2-cb05-48ce-bc49-9de556b93346  \n",
      "1   001c58d3-26ad-46b3-ab3a-c1e557d16821  \n",
      "2   001c8744-73c4-4b04-9364-22d31a10dbf1  \n",
      "3   00a119c4-d367-4607-b3c8-b237f2971bff  \n",
      "4   00c85316-bddf-4bcb-93f5-097adadd73c2  \n",
      "..                                   ...  \n",
      "95  13182f14-9b78-4c2d-b918-b50262a5fbbb  \n",
      "96  13343b60-2a7d-4dfa-81c1-69e4aa5aa462  \n",
      "97  13708adf-b4fc-4610-91a2-c7dcc03e48de  \n",
      "98  13f052cc-382b-437e-af19-84140b4a3a1e  \n",
      "99  1448928a-7205-455a-a3d1-0d84279aaa55  \n",
      "\n",
      "[100 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#To limit the number of input\n",
    "data=df.head(100)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yp/n2pvc9c13zq1_qk31djqb5d40000gn/T/ipykernel_91815/364022785.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m#Collect important information\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdoc_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'id'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mref_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'references'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mcitation_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'n_citation'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mabstract_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'abstract'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#Collect important information\n",
    "doc_list = list(data['id'].values)\n",
    "ref_list = list(data['references'].values)\n",
    "citation_list = list(data['n_citation'].values)\n",
    "abstract_list = list(data['abstract'].values)\n",
    "count = len(doc_list)\n",
    "print(len(doc_list))\n",
    "\n",
    "print(len(abstract_list),abstract_list)\n",
    "print(len(abstract_list[2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['The purpose of this study is to develop a learning tool for high school students studying the scientific aspects of information and communication net- works. More specifically, we focus on the basic principles of network proto- cols as the aim to develop our learning tool. Our tool gives students hands-on experience to help understand the basic principles of network protocols.', \"This paper describes the design and implementation of a methodology for the visualisation and hypothetical virtual reconstruction of Roman polychrome statuary for research purposes. The methodology is intended as an attempt to move beyond visualisations which are simply believable towards a more physically accurate approach. Accurate representations of polychrome statuary have great potential utility both as a means of illustrating existing interpretations and as a means of testing and revising developing hypotheses. The goal of this methodology is to propose a pipeline which incorporates a high degree of physical accuracy whilst also being practically applicable in a conventional archaeological research setting. The methodology is designed to allow the accurate visualisation of surviving objects and colourants as well as providing reliable methods for the hypothetical reconstruction of elements which no longer survive. The process proposed here is intended to limit the need for specialist recording equipment, utilising existing data and those data which can be collected using widely available technology. It is at present being implemented as part of the 'Statues in Context' project at Herculaneum and will be demonstrated here using the case study of a small area of the head of a painted female statue discovered at Herculaneum in 2006.\", 'This article applied GARCH model instead AR or ARMA model to compare with the standard BP and SVM in forecasting of the four international including two Asian stock markets indices.These models were evaluated on five performance metrics or criteria. Our experimental results showed the superiority of SVM and GARCH models, compared to the standard BP in forecasting of the four international stock markets indices.', 'Recent achievements in Natural Language Processing (NLP) and Psychology invoke the challenges to identify the insight of emotions. In the present study, we have identified different psychology related theme words while analyzing emotions on the interview data of ISEAR (International Survey of Emotion Antecedents and Reactions) research group. Primarily, we have developed a Graphical User Interface (GUI) to generate visual graphs for analyzing the impact of emotions with respect to different background, behavioral and physiological variables available in the ISEAR dataset. We have discussed some of the interesting results as observed from the generated visual graphs. On the other hand, different text clusters are identified from the interview statements by selecting individual as well as different combinations of the variables. Such textual clusters are used not only for retrieving the psychological theme words but also to classify the theme words into their respective emotion classes. In order to retrieve the psychological theme words from the text clusters, we have developed a rule based baseline system considering unigram based keyword spotting technique. The system has been evaluated based on a Top-n ranking strategy (where n=10, 20 or 30 most frequent theme words). Overall, the system achieves the average F-Scores of .42, .32, .36, .42, .35, .40 and .40 in identifying theme words with respect to Joy, Anger, Disgust, Fear, Guilt, Sadness and Shame emotion classes, respectively.', 'Most applications of the abstract interpretation framework[2] have been foranalyzing functional programs use functions on abstract values to approxi-mate functions, thus assuming that functions may be called at all arguments.When the abstract domain is ﬁnite, this approach can easily be generalizedto higher order functional languages as shown for example by [1]. In practicethis leads to combinatorial explosion problems as observed, for example, instrictness analysis of higher order functional languages.', \"This paper focuses on knowledge engineering for the development of a system that provides affective interaction in mobile devices. The system bases its inferences about users' emotions on user input evidence from the keyboard and the microphone of the mobile device. For this purpose different experimental studies have been conducted with the participation of mobile users and human experts. The experiments' aim was twofold. They aimed at revealing the criteria that are taken into account in each mode for emotion recognition as well as their weight of importance. The results of the studies are further used for the application of a multi-criteria decision making model.\", 'Xax is a browser plugin model that enables developers to leverage existing tools, libraries, and entire programs to deliver feature-rich applications on the web. Xax employs a novel combination of mechanisms that collectively provide security, OS-independence, performance, and support for legacy code. These mechanisms include memory-isolated native code execution behind a narrow syscall interface, an abstraction layer that provides a consistent binary interface across operating systems, system services via hooks to existing browser mechanisms, and lightweight modifications to existing tool chains and code bases. We demonstrate a variety of applications and libraries from existing code bases, in several languages, produced with various tool chains, running in multiple browsers on multiple operating systems. With roughly two person-weeks of effort, we ported 3.3 million lines of code to Xax, including a PDF viewer, a Python interpreter, a speech synthesizer, and an OpenGL pipeline.', 'In recent years, most of mobile phones have a function of pedestrian navigation guidance. It was reported that users sometimes feel anxiety because of low accuracy of the position estimation especially in urban area and delay of information updating. In order to reduce the anxiety, a route planning algorithm is proposed in this study, which weighs user\\'s difficulty (or easiness) of locating own current position as well as total physical distance of courses. The difficulty is estimated by valuation functions based on the \"recognizability\" and \"visibility\" of landmarks. An experimental study conducted in real situation using a prototype system to examine and refine the model for the optimal route planning. As the result, a modified model is proposed as a promising method of route planning for user\\'s easy wayfinding.', 'Previous language modeling approaches to information retrieval have focused primarily on single terms. The use of bigram models has been studied, but the restriction on word order and adjacency may not be justified for information retrieval. We propose a new language modeling approach to information retrieval that incorporates lexical affinities, or pairs of words that occur near each other, without a constraint on word order. The use of compound terms in the vector space model has been shown to outperform the vector model with only single terms (Nie & Dufort, 2002). We explore the use of compound terms in a language modeling approach, and compare our results with the vector space model, and unigram and bigram language model approaches.', 'Spatial encryption is a generic public-key cryptosystem where vectors play the role of public keys and secret keys are associated to affine spaces. Any secret key associated to a space can decrypt all ciphertexts encrypted for vectors in that space, and the delegation relation is defined by subspace inclusion. Though several constructions of spatial encryption schemes have been proposed in the literature, none of them are known to remain secure in the leakage-resilient setting, in which the adversary may be capable of learning limited additional information about the master secret key and other secret keys in the system. In this paper, we propose the first spatial encryption scheme achieving leakage resilience in the standard model, based on existing static assumptions over bilinear groups of composite order. Our new scheme is based on the leakageresilient HIBE scheme by Lewko, Rouselakis, and Waters in TCC 2011 and can be seen as a generalization of Moriyama-Doi spatial encryption scheme to the leakage-resilient setting.', 'In system operations the term rollback is often used to imply that arbitrary changes can be reversed i.e. ‘rolled back’ from an erroneous state to a previously known acceptable state. We show that this assumption is flawed and discuss error-correction schemes based on absolute rather than relative change.#R##N##R##N#Insight may be gained by relating change management to the theory of computation. To this end, we reformulate previously-defined ‘convergent change operators’ of Burgess into the language of groups and rings. We show that, in this form, the problem of rollback from a convergent operation becomes equivalent to that of ‘division by zero’ in computation. Hence, we discuss how recent work by Bergstra and Tucker on zero-totalized fields helps to clear up long-standing confusion about the options for ‘rollback’ in change management.', 'Business strategy should be well understood in order to support an enterprise to achieve its vision and to define an architecture supporting that vision. While business views are identified in many Enterprise Architecture (EA) proposals, business strategy formulations from the area of Strategic Management are overlooked. Thus, IT solutions cannot be traced back to business strategy in a clear and unambiguous way. Our intended proposal, a Unified Business Strategy Meta-Model (UBSMM), aims at establishing such a link. UBSMM is a formalization of the integration of known business strategy formulations with precise semantics enabling its model-level usage to provide strategic awareness to Enterprise Architecture. In this paper we present the development process of UBSMM, and further, we propose conceptual relationships towards Enterprise Architecture (EA).', 'There are a number of alternative techniques for dealing with uncertainty. Here we discuss rough set, fuzzy rough set, and intuitionistic rough set approaches andhowtoincorporateuncertaintymanagementusingthemintherelationaldatabase model. The impacts of rough set techniques on fundamental database concepts such as functional dependencies and information theory are also considered.', 'Breast cancer is the most common form of cancer in women. Early diagnosis is necessary for effective treatment and therefore of crucial importance. Medical thermography has been demonstrated an effective and inexpensive method for detecting breast cancer, in particular in early stages and in dense tissue. In this paper, we propose a medical decision support system based on analysing bilateral asymmetries in breast thermograms. The underlying data is imbalanced, as the number of benign cases significantly exceeds that of malignant ones, which will lead to problems for conventional pattern recognition algorithms. To address this, we propose an ensemble classifier system which is based on the idea of Clustering and Selection. The feature space, which is derived from a series of image symmetry features, is partitioned in order to decompose the problem into a set of simpler decision areas. We then delegate a locally competent classifier to each of the generated clusters. The set of predictors is composed of both standard models as well as models dedicated to imbalanced classification, so that we are able to employ a specialised classifier to clusters that show high class imbalance, while maintaining a high specificity for other clusters. We demonstrate that our method provides excellent classification performance and that it statistically outperforms several state-of-the-art ensembles dedicated to imbalanced problems.', 'The development of an automated system for the quality assessment of aerodrome ground lighting (AGL), in accordance with associated standards and recommendations, is presented. The system is composed of an image sensor, placed inside the cockpit of an aircraft to record images of the AGL during a normal descent to an aerodrome. A model-based methodology is used to ascertain the optimum match between a template of the AGL and the actual image data in order to calculate the position and orientation of the camera at the instant the image was acquired. The camera position and orientation data are used along with the pixel grey level for each imaged luminaire, to estimate a value for the luminous intensity of a given luminaire. This can then be compared with the expected brightness for that luminaire to ensure it is operating to the required standards. As such, a metric for the quality of the AGL pattern is determined. Experiments on real image data is presented to demonstrate the application and effectiveness of the system.', 'Quality specified image retrieval is helpful to improve the user experiences in mobile searching and social media sharing. However, the model for evaluating the quality of the user generated images, which are popular in social media sharing, remains unexploited. In this paper, we propose a scheme for quality assessment on user generated image. The scheme is formed by four attribute dimensions, including intrinsic quality, favorability, relevancy and accessibility of images. Each of the dimensions is defined and modeled to pool a final quality score of a user generated image. The proposed scheme can reveal the quality of user generated image in comprehensive manner. Experimental results show that the scores obtained by our scheme have high correlation coefficients with the benchmark data. Therefore, our scheme is suitable for quality specified image retrieval on mobile applications.', 'We discuss traveling wave solutions to the Yukawa equations, a system of nonlinear partial differential equations which has applications to meson–nucleon interactions. The Yukawa equations are converted to a six-dimensional dynamical system, which is then studied for various values of the wave speed and mass parameter. The stability of the solutions is discussed, and the methods of competitive modes is used to describe parameter regimes for which chaotic behaviors may appear. Numerical solutions are employed to better demonstrate the dependence of traveling wave solutions on the physical parameters in the Yukawa model. We find a variety of interesting behaviors in the system, a few of which we demonstrate graphically, which depend upon the relative strength of the mass parameter to the wave speed as well as the initial data.', 'In this paper, we investigate the multi-layer topology preserving mapping for K-means. We present a Multi-layer Topology Preserving Mapping (MTPM) based on the idea of deep architectures. We demonstrate that the MTPM output can be used to discover the number of clusters for K-means and initialize the prototypes of K-means more reasonably. Also, K-means clusters the data based on the discovered underlying structure of the data by the MTPM. The standard wine data set is used to test our algorithm. We finally analyse a real biological data set with no prior clustering information available.', 'The paper discusses the design principles and current status of a natural language front end for access to data bases. This Is based on the use, first, of a semantically-oriented question analyser exploiting general, language-wide semantic categories and patterns, rather than data base-specific ones; and, second, of a data base-oriented translation component for obtaining search specifications from the meaning representations for questions derived by the analyser. This approach is motivated by the desire to reduce the effort of providing data base-specific material for the front end, by the belief that a general analyser is well suited to the \"casual\" data base user, and by the assumption that the rich semantic apparatus used will be both adequate as a means of analysis and appropriate as a tool for linking the characterisations of input and data language items. The paper describes this approach in more detail, with emphasis on the existing, tested, analyser.', 'State-space explosion is a major obstacle in verification of time-critical distributed systems. An important factor with a negative influence on the tractability of the analysis is the size of constants that clocks are compared to. This problem is particularly accented in ex- plicit state-space exploration techniques. We suggest an approximation method for reducing the size of constants present in the model. The proposed method is developed for Timed-Arc Petri Nets and creates an under-approximation or an over-approximation of the model behaviour. The verification of approximated Petri net models can be considerably faster but it does not in general guarantee conclusive answers. We im- plement the algorithms within the open-source model checker TAPAAL and demonstrate on a number of experiments that our approximation techniques often result in a significant speed-up of the verification.', 'We focus on covariance criteria for flnding a suitable sub- space for regression in a reproducing kernel Hilbert space: kernel princi- pal component analysis, kernel partial least squares and kernel canonical correlation analysis, and we demonstrate how this flts within a more gen- eral context of subspace regression. For the kernel partial least squares case some variants are considered and the methods are illustrated and compared on a number of examples.', 'In recent years, several advanced methods for image steganalysis were proposed. During research process, some concerns are more and more addressed by steganalyzer. In this paper, we focus on several of these concerns. The first one is how to utilize SVM classifier in practical steganalysis, we use clustering analysis to divide training samples and train several SVM for detecting stego image. In this part we also discussed building an image database that can be used for evaluating steganography/steganalysis fairly. The second is how to designed proper classifier for steganalysis, especially how to take information of cover/stego image pair into account. We will discuss several notions regard to these two concerns.', 'This paper presents an experimental evaluation of a rapid, adaptive assessment of the difference threshold (DL) of passive metacar- pophalangeal index finger joint flexion using a robotic device. Parameter Estimation by Sequential Testing (PEST) is compared to the method of constant stimuli (MOCS) using a two-alternative forced-choice par- adigm. The pilot study with 13 healthy subjects provided DLs within similar ranges for MOCS and PEST, averaging at 2.15 ◦ ± 0.77 ◦ and 1.73 ◦ ±0.78 ◦ , respectively, in accordance with the literature. However, no significant correlation was found between the two methods (r(11) = 0.09, p =0 .762). The average number of trials required for PEST to converge was 58.7± 17.6, and significantly lower compared to 120 trials for MOCS ( p< 0.001), leading to an assessment time of under 15 min. These results suggest that rapid, adaptive methods, such as PEST, could be success- fully implemented in novel robotic tools for clinical assessment of sensory deficits.', 'The paper describes user behavior as a result of introducing monetization in the freemium educational online platform. Monetization resulted in alternative system growth mechanisms, causing viral increase in the number of users. Given different options, users choose the most advantageous and simple ones for them. System metrics in terms of the K-factor was utilized as an indicator of the system user base growth. The weekly K-factor almost doubled as a result of monetization introduction. Monetization and viral growth can be both competing and complementary mechanisms for the system growth.', 'The acquisition of concepts induced by structural descriptions of pictures is discussed and a representation scheme is presented which allows the construction of various abstractions based on different points of views and their storage in a simulated associative memory.', 'We study a hypergraph transversal computation: given a hypergraph, the problem is to generate all minimal transversals. This problem is related to many applications in computer science and vari- ous algorithms have been proposed. We present a new efficient algorithm using the compressed data structures BDDs and ZDDs, and we analyze the time complexity for it. By conducting computational experiments, we show that our algorithm is highly competitive with existing algorithms.', 'We present the application of software process modeling and simulation using an agent-based approach to a real case study of soft- ware maintenance. The original process used PSP/TSP; it spent a large amount of time estimating in advance maintenance requests, and needed to be greatly improved. To this purpose, a Kanban system was success- fully implemented, that demonstrated to be able to substantially improve the process without giving up PSP/TSP. We customized the simulator and, using input data with the same characteristics of the real ones, we were able to obtain results very similar to that of the processes of the case study, in particular of the original process. We also simulated, using the same input data, the possible application of the Scrum process to the same data, showing results comparable to the Kanban process.', 'Entailment pairs are sentence pairs of a premise and a hypothesis, where the premise textually entails the hypothesis. Such sentence pairs are important for the development of Textual Entailment systems. In this paper, we take a closer look at a prominent strategy for their automatic acquisition from newspaper corpora, pairing first sentences of articles with their titles. We propose a simple logistic regression model that incorporates and extends this heuristic and investigate its robustness across three languages and three domains. We manage to identify two predictors which predict entailment pairs with a fairly high accuracy across all languages. However, we find that robustness across domains within a language is more difficult to achieve.', 'Resource tagging has become an integral and important feature in enabling community users to easily access relevant content in a timely manner. Various methods have been proposed and implemented to optimize the identification of and access to tags used to characterize resources across different types of social web-based communities. While these user-focused tagging methods have shown promise in their limited application, they do not transfer well to internal business applications where the cost, time, tagged content, and user resources needed to implement them is prohibitive. This paper provides a case study of the process, tools, and methods used to engage users in the development and management of a tag taxonomy (folksontology) used to characterize content in an internal technical support community in the Cisco Global Technology Center.', 'This paper addresses an optimization-based approach for the design of RF integrated inductors. The methodology presented deals with the complexity of the design problem by formulating it as a multi-objective optimization. The multi-modal nature of the underlying functions combined with the need to be able to explore design trade-offs leads to the use of niching methods. This allows exploring not only the best trade-off solutions lying on the Pareto-optimum surface but also the quasi-optimum solutions that would be otherwise discarded. In this paper we take advantage of the niching properties of lbest PSO algorithm using ring topology to devise a simple optimizer able to find the local-optima. For the efficiency of the process analytical models are used for the passive/active devices. In spite the use of physics-based analytical expressions for the evaluation of the lumped elements, the variability of the process parameters is ignored in the optimization stage due to the significant computational burden it involves. Thus in the final stage both the Pareto- optimum solutions and the quasi-optimum solutions are evaluated with respect to the sensitivity to process parameter variations.', 'Process-based context-aware applications are increasingly be- coming more complex and dynamic. Besides the large sets of process vari- ants to be managed in such dynamic systems, process variants need to be context sensitive in order to accommodate new user requirements and intrinsic complexity. This paradigm shift forces us to defer decisions to runtime where process variants must be customized and executed based on a recognized context. However, there exists a lack of deferral of the entire process variant configuration and execution to perform an auto- mated decision of subsequent variation points at runtime. In this paper, we present a holistic methodology to automatically resolve process vari- ability at runtime. The proposed solution performs a staged configuration considering static and dynamic context data to accomplish effective de- cision making. We demonstrate our approach by exemplifying a storage operation process in a smart logistics scenario. Our evaluation demon- strates the performance and scalability results of our methodology.', 'We investigate the problem of inserting rhetorical predicates (e.g. \"to present\", \"to discuss\", \"to indicate\", \"to show\") during non extractive summary generation and compare various algorithms for the task which we trained over a set of human written summaries. The algorithms which use a set of features previously introduced in the summarization literature achieve between 57% to 62% accuracy depending on the machine learning algorithm used. We draw conclusions with respect to the use of context during predicate prediction.', 'Gene tree parsimony (GTP) problems infer species supertrees from a collection of rooted gene trees that are confounded by evolutionary events like gene duplication, gene duplication and loss, and deep coalescence. These problems are NP-complete, and consequently, they often are addressed by effective local search heuristics that perform a stepwise search of the tree space, where each step is guided by an exact solution to an instance of a local search problem. Still, GTP problems require rooted input gene trees; however, in practice, most phylogenetic methods infer unrooted gene trees and it may be difficult to root correctly. In this work, we (i) define the first local NNI search problems to solve heuristically the GTP equivalents for unrooted input gene trees, called unrooted GTP problems, and (ii) describe linear time algorithms for these local search problems. We implemented the first NNI based local search heuristics for unrooted GTP problems, which enable analyses for thousands of genes. Further, analysis of a large plant data set using the unrooted NNI search provides support for an intriguing new hypothesis regarding the evolutionary relationships among major groups of flowering plants.', \"We propose and show a parallel and distributed runtime environment for multi-agent systems that provides spatial agent migration ability by employing code morphing. The focus of the application scenario lies on sensor networks and low-power, resource-aware single System-On-Chip designs. An agent approach provides stronger autonomy than a traditional object or remote-procedure-call based approach. Agents can decide for themselves which actions are performed, and they are capable of reacting on the environment and other agents with flexible behaviour. Data processing nodes exchange code rather than data to transfer information. A part of the state of an agent is preserved within its own program code, which also implements the agent's migration functionality. The practicability of the approach is shown using a simple distributed Sobel filter as an example.\", 'Introduction: Public health surveillance systems need to be refined. We intend to use a generic approach for early identification of patients with severe influenza-like illness (ILI) by calculating a score that estimates a patient’s disease-severity. Accordingly, we built the Intelligent Severity Score Estimation Model (ISSEM), structured so that the inference process would reflect experts’ decisionmaking logic. Each patient’s disease-severity score is calculated from numbers of respiratory ICD9 encounters, and laboratory, radiologic, and prescription-therapeutic orders in the EMR. Other ISSEM components include chronic disease evidence, probability of immunodeficiency, and the provider’s general practice-behavior patterns. Results: Sensitivity was determined from 200 randomly selected patients with upper- and lowerrespiratory tract ILI; specificity, from 300 randomly selected patients with URI only. For different age groups, ISSEM sensitivity ranged between 90% and 95%; specificity was 72% to 84%. Conclusion: Our preliminary assessment of ISSEM performance demonstrated 93.5% sensitivity and 77.3% specificity across all age groups. Background', \"Data skewness is a challenge encountered, in particular, when apply- ing supervised machine learning approaches in various domains, such as in healthcare and biomedical information engineering. Evidence Based Medicine (EBM) is a clinical strategy for prescribing treatment based on current best evi- dence for individual patients. Clinicians need to query publication repositories in order to find the best evidence to support their decision-making processes. This sophisticated information is materialised in the form of scientific artefacts in scholarly publications and the automatic extraction of these artefacts is a technical challenge for current generic search engines. Many classification ap- proaches have been proposed for identifying key scientific artefacts in EBM, however their performance is affected by the imbalanced characteristic of data in this domain. In this paper, we present four data balancing approaches applied in a binary ensemble classifier framework for classifying scientific artefacts in the EBM domain. Our balancing approaches improve the ensemble classifier's F-score by up to 15% for classes of scientific artefacts with extremely low cov- erage in the domain. In addition, we propose a classifier selection method for choosing the best classifier based on the distributional feature of classes. The resulting classifiers show improved classification performances when compared to state of the art approaches.\", 'Distributed computing systems are of huge importance in a number of recently established and future functions in computer science. For example, they are vital to banking applications, communication of electronic systems, air trafﬁc control, manufacturing automation, biomedical operation works, space monitoring systems and robotics information systems. As the nature of computing comes to be increasingly directed towards intelligence and autonomy, intelligent computations will be the key for all future applications. Intelligent distributed computing will become the base for the growth of an innovative generation of intelligent distributed systems. Nowadays, research centres require the development of architectures of intelligent and collaborated systems; these systems must be capable of solving problems by themselves to save processing time and reduce costs. Building an intelligent style of distributed computing that controls the whole distributed system requires communications that must be based on a completely consistent system. The model of the ideal system to be adopted in building an intelligent distributed computing structure is the human body system, speciﬁcally the body’s cells. As an artiﬁcial and virtual simulation of the high degree of intelligence that controls the body’s cells, this chapter proposes a Cell-Oriented Computing model as a solution to accomplish the desired Intelligent Distributed Computing system.', \"In this paper we re-examine the well known problem of asynchronous black hole search in a ring. It is well known that at least 2 agents are needed and the total number of agents' moves is at least Ω(n log n); solutions indeed exist that allow a team of two agents to locate the black hole with the asymptotically optimal cost of Θ(n log n) moves.#R##N##R##N#In this paper we first of all determine the exact move complexity of black hole search in an asynchronous ring. In fact, we prove that 3n log3 n-O(n) moves are necessary. We then present a novel algorithm that allows two agents to locate the black hole with at most 3n log3 n + O(n) moves, improving the existing upper bounds, and matching the lower bound up to the constant of proportionality. Finally we show how to modify the protocol so to achieve asymptotically optimal time complexity Θ(n), still with 3n log3 n + O(n) moves; this improves upon all existing time-optimal protocols, which require O(n2) moves. This protocol is the first that is optimal with respect to all three complexity measures: size (number of agents), cost (number of moves) and time; in particular, its cost and size complexities match the lower bounds up to the constant.\", 'This paper presents WorkCellSimulator, a software platform that allows to manage an environment for the simulation of robot tasks. It uses the most advanced artificial intelligence algorithms in order to define the production process, by controlling one or more robot manipulators and machineries present in the work cell. The main goal of this software is to assist the user in defining customized production processes which involve specific automated cells. It has been developed by IT+Robotics, a spin-off company of the University of Padua, founded in 2005 from the collaboration between young researchers in the field of Robotics and a group of professors from the Department of Information Engineering, University of Padua.', 'Unsupervised keyphrase extraction techniques generally consist of candidate phrase selection and ranking techniques. Previous studies treat the candidate phrase selection and ranking as a whole, while the effectiveness of identifying candidate phrases and the impact on ranking algorithms have remained undiscovered. This paper surveys common candidate selection techniques and analyses the effect on the performance of ranking algorithms from different candidate selection approaches. Our evaluation shows that candidate selection approaches with better coverage and accuracy can boost the performance of the ranking algorithms.', 'We propose an indexing data structure based on a novel variation of Bloom filters. Signature files have been proposed in the past as a method to index large text databases though they suffer from a high false positive error problem. In this paper we introduce COCA Filters, a new type of Bloom filters which exploits the co-occurrence probability of words in documents to reduce the false positive error. We show experimentally that by using this technique we can reduce the false positive error by up to 21.6 times for the same index size. Furthermore Bloom filters can be replaced by COCA filters wherever the co-occurrence of any two members of the universe is identifiable.', 'The Shared Pathology Informatics Network (SPIN), a research initiative of the National Cancer Institute, will allow for the retrieval of more than 4 million pathology reports and specimens. In this paper, we describe the special query tool as developed for the Indianapolis/Regenstrief SPIN node, integrated into the ever-expanding Indiana Network for Patient care (INPC). This query tool allows for the retrieval of de-identified data sets using complex logic, auto-coded final diagnoses, and intrinsically supports multiple types of statistical analyses. The new SPIN/INPC database represents a new generation of the Regenstrief Medical Record system – a centralized, but federated system of repositories.', 'Modular exponentiation is a cornerstone operation to several public-key cryptography systems such as the RSA. It is performed using successive modular multiplications. The latter is time consuming for large operands. Accelerating public-key cryptography software or hardware needs reducing the total number of modular multiplication needed. This paper introduces a novel idea based on genetic algorithms for evolving an optimal addition chain that allows one to perform precomputations necessary in the window modular exponentiation methods. The obtained addition chain allows one to perform exponentiation with a minimal number of multiplication and hence implementing efficiently the exponentiation operation. We compare our results with those obtained using the algorithm of Brun.', 'This paper presents the systems that we participated with in the Semantic Text Similarity task at SEMEVAL 2012. Based on prior research in semantic similarity and relatedness, we combine various methods in a machine learning framework. The three variations submitted during the task evaluation period ranked number 5, 9 and 14 among the 89 participating systems. Our evaluations show that corpus-based methods display a more robust behavior on the training data, yet combining a variety of methods allows a learning algorithm to achieve a superior decision than that achievable by any of the individual parts.', 'Comunicacio presentada a 9th Annual Conference of the International Speech Communication Association celebrada a Brisbane (Australia) del  22 al 26 de setembre de 2008.', 'PiQASso is a Question Answering system based on a combination of modern IR techniques and a series of semantic filters for selecting paragraphs containing a justifiable answer. Semantic filtering is based on several NLP tools, including a dependency-based parser, a POS tagger, a NE tagger and a lexical database. Semantic analysis of questions is performed in order to extract key word used in retrieval queries and to detect the expected answer type. Semantic analysis of retrieved paragraphs includes checking the presence of entities of the expected answer type and extracting logical relations between words. A paragraph is considered to justify an answer if similar relations are present in the question. When no answer passes the filters, the process is repeated applying further levels of query expansions in order to increase recall. We discuss results and limitations of the current implementation.', \"We introduce data musicalization as a novel approach to aid analysis and understanding of sleep measurement data. Data musicalization is the process of automatically composing novel music, with given data used to guide the process. We present Sleep Musicalization, a methodology that reads a signal from state-of-the-art mattress sensor, uses highly non-trivial data analysis methods to measure sleep from the signal, and then composes music from the measurements. As a result, Sleep Musicalization produces music that reflects the user's sleep during a night and complements visualizations of sleep measurements. The ultimate goal is to help users improve their sleep and well-being. For practical use and later evaluation of the methodology, we have built a public web service at http://sleepmusicalization.net for users of the sleep sensors.\", 'Mobile health (mHealth) has been receiving more and more attention recently as an emerging paradigm that brings together the evolution of advanced mobile and wireless communication technologies with the vision of \"connected health\" aiming to deliver the right care in the right place at the right time. However, there are several cardinal problems hampering the successful and widespread deployment of mHealth services from the mobile networking perspective. On one hand, issues of continuous wireless connectivity and mobility management must be solved in future heterogeneous mobile Internet architectures with ever growing traffic demands. On the other hand, Quality of Service (QoS) and Quality of Experience (QoE) must be guaranteed in a reliable, robust and diagnostically acceptable way. In this paper we propose a context- and content-aware, jointly optimized, distributed dynamic mobility management architecture to cope with the future traffic explosion and meet the medical QoS/QoE requirements in varying environments.', 'Utilization of camera systems for surveillance tasks (e. g. traffic monitoring) has become a standard procedure and has been in use for over 20 years. However, most of the cameras are operated locally and data analyzed manually. Locally means here a limited field of view and that the image sequences are processed independently from other cameras. For the enlargement of the observation area and to avoid occlusions and non-accessible areas multiple camera systems with overlapping and non-overlapping cameras are used. The joint processing of image sequences of a multi-camera system is a scientific and technical challenge. The processing is divided traditionally into camera calibration, object detection, tracking and interpretation. The fusion of information from different cameras is carried out in the world coordinate system. To reduce the network load, a distributed processing concept can be implemented.#R##N##R##N#Object detection and tracking are fundamental image processing tasks for scene evaluation. Situation assessments are based mainly on characteristic local movement patterns (e.g. directions and speed), from which trajectories are derived. It is possible to recognize atypical movement patterns of each detected object by comparing local properties of the trajectories. Interaction of different objects can also be predicted with an additional classification algorithm.#R##N##R##N#This presentation discusses trajectory based recognition algorithms for atypical event detection in multi object scenes to obtain area based types of information (e.g. maps of speed patterns, trajectory curvatures or erratic movements) and shows that two-dimensional areal data analysis of moving objects with multiple cameras offers new possibilities for situational analysis.', \"The Web is evolving from a repository for text and images to a provider of services - both information-providing services, and services that have some effect on the world. Today's Web was designed primarily for human use. To enable reliable, large-scale automated interoperation of services by computer programs or agents, the properties, capabilities, interfaces and effects of Web services must be understandable to computers. In this paper we propose a vision and a partial realization of precisely this. We propose markup of Web services in the DAML family of semantic Web markup languages. Our markup of Web services enables a wide variety of agent technologies for automated Web service discovery, execution, composition and interoperation. We present one logic-based agent technology for service composition, predicated on the use of reusable, task-specific, high-level generic procedures and user-specific customizing constraints.\", 'Gaze tracking is an aspect of human-computer interaction still growing in popularity. Tracking human eye fixation points can help control user interfaces and eventually may help in the interface evalu- ation or optimization. Unfortunately professional eye-trackers are very expensive and thus hardly available for researchers and small companies. The paper presents very effective, exponentially smoothed, low cost, ap- pearance based, improved gaze tracking method. The method achieves very high absolute precision (1 deg) at 20 fps, exploiting a simple HD web camera with reasonable environment restrictions. The paper de- scribes results of experimental tests, both static on absolute gaze point estimation, and dynamic on gaze controlled path following.', 'The construction of a program that generates crossword puzzles is discussed. As in a recent paper by Dechter and Meiri, we make an experimental comparison of various search techniques. The conclusions to which we come differ from theirs in some areas - although we agree that directional arc consistency is better than path-consistency or other forms of lookahead, and that backjumping is to be preferred to backtracking, we disagree in that we believe dynamic ordering of the constraints to be necessary in the solution of more difficult problems.', \"Dans le cadre de la theorie des traces, un graphe de dependance represente le comportement d'un systeme distribue (par exemple un reseau de Petri) par analogie avec la relation mot-automate dans le cas sequentiel. Un langage reconnaissable de graphes de dependances represente ainsi l'ensemble de tous les comportements d'un systeme distribue satisfaisant des conditions de regularite. Dans cet article nous caracterisons les languages de graphes obtenus a partir des precedents par suppression des etiquettes sur les sommets\", \"The mediaeval logic of Aristotelian privation, represented by Ockham's expositionof All A is non-P as All S is of a type T that is naturally P and no S is P, iscritically evaluated as an account of privative negation. It is argued that there aretwo senses of privative negation: (1) an intensifier (as in subhuman), the dualof Neoplatonic hypernegation (superhuman), which is studied in linguistics asan operator on scalar adjectives, and (2) a (often lexicalized) Boolean complementrelative to the extension of a privative negation in sense (1) (e.g., Brute). Thissecond sense, which is the privative negation discussed in modern linguistics, isshown to be Aristotle's. It is argued that Ockham's exposition fails to capture muchof the logic of Aristotelian privation due to limitations in the expressive power of thesyllogistic.\", 'An asymmetric relation, called a weak similarity relation, is introduced as a more realistic relation in representing the relationship between two elements of data in a real-world application. A conditional probability relation is considered as a concrete example of the weak similarity relation by which a covering of the universe is provided as a generalization of a disjoint partition. A generalized concept of rough approximations regarded as a kind of fuzzy rough set is proposed and defined based on the covering of the universe. Additionally, a more generalized fuzzy rough approximation of a given fuzzy set is proposed and discussed as an alternative to provide interval-valued fuzzy sets. Their properties are examined.', 'This chapter considers ‘T’ to be a countable complete ω -stable theory. The notion “dimension” is used for classes of non-orthogonal regular types over models. T is nonmultidimensional if the number μ (T) of dimensions is bounded. Models of non-multidimensional ω-stable theories can be classified by μ (T)-tuples of cardinals. The chapter also presents some preliminaries from stability theory and focuses on the algebra of models of Th(F c (p n , N  O )). The chapter also discusses the Lascar rank computation and dimensions.', 'Channel correlation has the effect to reduce the sum rate and user capacity of multiuser multi-input multi-output (MU-MIMO) systems considerably. In this paper, receive antenna selection is proposed for uplink MU-MIMO system to maximize the sum rate and to maintain high user capacity over correlated Rayleigh fading channel. Two antenna selection criteria are presented to tradeoff the computational complexity and performance. Capacity based selection criterion (CBSC) provides optimal performance at the cost of high complexity compared with the suboptimal norm based selection criterion (NBSC). Simulation results demonstrate and validate the effectiveness of proposed method compared with conventional MU-MIMO systems.', 'Finding information is a problem shared by people and intelligent systems. This paper describes an experiment combining both human and machine aspects in a knowledgebased system to help people find information in text. Unlike many previous attempts, this system demonstrates a substantial improvement in search effectiveness by using linguistic and world knowledge and exploiting sophisticated knowledge representation techniques. It is also an example of practical subsumption technology on a large scale and with domainindependent knowledge. Results from this experiment are relevant to general problems of knowledge-based reasoning with large-scale knowledge bases.', 'Open learner models (OLMs) available independently from specific tutoring or guidance, such as an intelligent tutoring system may provide, can encourage learners to take greater responsibility for learning., Our results suggest that finer grained OLM information, in this context, can support learners in identifying strengths/weaknesses, planning and focussing learning, when different OLM granularities exist. Learners drew regular comparison between OLM and domain information, showing the flexibility of interaction to be important.', 'Conversational Agents have been shown to be effective tutors in a wide range of educational domains. However, these agents are often ignored and abused in collaborative learning scenarios involving multiple students. In our work presented here, we design and evaluate interaction strategies motivated from prior research in small group communication. We will discuss how such strategies can be implemented in agents. As a first step towards evaluating agents that can interact socially, we report results showing that human tutors employing these strategies are able to cover more concepts with the students besides being rated as better integrated, likeable and friendlier.', 'In this work, we study simultaneously resettable arguments of knowledge. As our main result, we show a construction of a constant-round simultaneously resettable witness-indistinguishable argument of knowledge (simresWIAoK, for short) for any NP language. We also show two applications of simresWIAoK: the first constant-round simultaneously resettable zero-knowledge argument of knowledge in the Bare Public-Key Model; and the first simultaneously resettable identification scheme which follows the knowledge extraction paradigm.', 'The tool USE (UML-based Specification Environment) supports analysts,#R##N#designers and developers in executing UML models and checking OCL#R##N#constraints and thus enables them to employ model-driven techniques#R##N#for software production. USE has been developed since 1998 at the#R##N#University of Bremen. This paper will discuss to what extent and how#R##N#USE relates to the questions and topics (Model quality, Modelling#R##N#method, Model Effectiveness, Model Maintainability) raised for this#R##N#seminar.', 'Rough set theory has been attracting researchers and practitioners over three decades. The theory and its applications experienced unprecedented prosperity especially in the recent ten years. It is essential to explore and review the progress made in the field of rough sets. Mainly based on Web of Science database, we analyze the prolific authors, impact authors, impact groups, and the most impact papers in the past three decades. In addition, we also examine rough set development in the recent five years. One of the goals of this article is to use scientometrics approaches to study three decade research in rough sets. We review the historic growth of rough sets and elaborate on recent development status in this field.', 'The appeals for interoperable and decentralized Electronic Identity Management are rapidly increasing, especially since their contribution towards interoperability across the entire \"electronic\" public sector, effective information sharing and simplified access to electronic services, is unquestioned. This paper presents an efficient and user-centric method for storing multiple users\\' identifiers in X.509 digital certificates while preserving their confidentiality, allowing for interoperable user identification in environments where users cannot be identified by an all embracing unique identifier.', 'Four front-end processing techniques developed for noise robust speech recognition are tested with the Aurora 2 database. These techniques include three previously published algorithms: variable frame rate analysis [Zhu and Alwan, 2000], peak isolation [Strope and Alwan, 1997], and harmonic demodulation [Zhu and Alwan, 2000], and a new technique for peak-to-valley ratio locking. Our previous work has focused on isolated digit recognition. In this paper, these algorithms are modified for recognition of connected digits. Recognition results with the Aurora 2 database show that a combination of these four techniques results in 40% error rate reduction when compared to the baseline MFCC front-end for the clean training condition, with no significant increase in computational complexity.', \"Relevance feedback algorithm is proposed to be an effective way to improve the precision of information retrieval. However, most researches about relevance feedback are based on vector space model, which can't be used in other more complicated and powerful models, such as language model and logic model. Meanwhile, other researches are conceptually restricted to the view of a query as a set of terms, and so cannot be naturally applied to more general case when the query is considered as a sequence of terms and the frequency information of a query tern is considered. In this paper, we mainly focuses on relevant feedback Algorithm based on language model. We use a mixture model to describe the process of generating document and use EM to solve model's parameters. Our research also employs semi-supervised learning to calculate collection model and proposes an effective way to obtain feedback from irrelevant documents to improve our algorithm.\", 'This paper discloses the potential of OWL (Web Ontology Language) ontologies for generation of rules. The main purpose of this paper is to identify new types of rules, which may be generated from OWL ontologies. Rules, generated from OWL ontologies, are necessary for the functioning of the Semantic Web Expert System. It is expected that the Semantic Web Expert System (SWES) will be able to process ontologies from the Web with the purpose to supplement or even to develop its knowledge base.', 'It is well known that, as the dimensionality of a metric space increases, metric search techniques become less effective and the cost of indexing mechanisms becomes greater than the saving they give. This is due to the so-called curse of dimensionality. One effect of increasing dimensionality is that the ratio of unit hypersphere to unit hypercube volume decreases rapidly, making the solution to a similarity query (the query ball, or hypersphere) ever more difficult to identify by using metric invariants such as triangle inequality. In this paper we take a different approach, by identifying points within a query polyhedron rather than a ball. We show how this can be achieved by constructing a surrogate metric space, such that a query ball in the surrogate space corresponds to a polyhedron in the original space. If the polyhedron contains the ball, the overall cost of the query is likely to be increased in high dimensions; however, we show that shrinking the polyhedron can capture a surprisingly high proportion of the points within the ball, whilst at the same time giving a more efficient, and more scalable, search. We show results which confirm our underlying hypothesis. In some cases we can retrieve significant volumes of query results from spaces which are otherwise intractable.', \"Many annotation tasks in computational linguistics are tackled with manually constructed pipelines of algorithms. In real-time tasks where information needs are stated and addressed ad-hoc, however, manual construction is infeasible. This paper presents an artificial intelligence approach to automatically construct annotation pipelines for given information needs and quality prioritizations. Based on an abstract ontological model, we use partial order planning to select a pipeline's algorithms and informed search to obtain an efficient pipeline schedule. We realized the approach as an expert system on top of Apache UIMA, which offers evidence that pipelines can be constructed ad-hoc in near-zero time.\", 'Simple Conceptual Graphs (SGs) are used to represent entities and relations between these entities: they can be translated into positive, conjunctive, existential first-order logics, without function symbols. Sound and complete reasonings w.r.t. associated logic formulas are obtained through a kind of graph homomorphism called projection. Conceptual Graphs Rules (or CG rules) are a standard extension to SGs, keeping sound and complete reasonings w.r.t. associated logic formulas (they have the same form as tuple generating dependencies in database): these graphs represent knowledge of the form “IF ... THEN”. We present here an optimization of the natural forward chaining algorithm for CG rules. Generating a graph of rules dependencies makes the following sequences of rule applications far more efficient, and the structure of this graph can be used to obtain new decidability results.', 'In terms of supervised face recognition, linear discriminant analysis (LDA) has been viewed as one of the most popular approaches during the past years. In this paper, taking advantage of the equivalence between LDA and the least square problem, we propose a new fusion method for face classification, based on the combination of least square solutions for local mean and local texture into multiple optimization problems. Extensive experiments on AR_Gray and Yale face database indicate the competitive performance of the proposed method, compared to the traditional LDA.', 'Presently, retrieving images from a digital library requires different retrieval techniques to those used to retrieve text documents. In this paper, we demonstrate the possibility of converting the contents of images into texts, which enables us to utilise text-base retrieval techniques for image retrieval. The potential advantages and applications of this approach are also illustrated in this paper.', \"We present an architecture and software framework for semantic allies: Semantic systems that complement existing software applications with semantic services and interactions based on a background ontology. On the one hand, our Semantic Alliance framework follows an invasive approach: Users can profit from semantic technology without having to leave their accustomed workflows and tools. On the other hand, Semantic Alliance offers a largely application-independent way of extending existing (open API) applications with MKM technologies. Semantic Alliance framework presented in this paper consists of three components: i.) a universal semantic interaction manager for given abstract document types, ii.) a set of thin APIs realized as invasive extensions to particular applications, and iii.) a set of renderer components for existing semantic services. We validate the Semantic Alliance approach by instantiating it with a spreadsheet-specific interaction manager, thin APIs for LibreOffice Calc 3.4 and MS Excel'10, and a browser-based renderer.\", 'Organizations are a powerful way to coordinate complex behavior in human society. Thus, human organizations can serve as a basis for better understanding and designing open multi-agent systems. Organizational models have been recently used in agent theory for modelling coordination in open systems and to ensure social order in multi-agent system applications. This work discusses several organizational features of organization-oriented multiagent system methodologies and analyzes whether they take into account human organizational designs. Moreover, several guidelines that any organization-oriented MAS methodology must take into account are proposed.', \"Accurately locating users in a wireless environment is an important task for many pervasive computing and AI applications, such as activity recognition. In a WiFi environment, a mobile device can be localized using signals received from various transmitters, such as access points (APs). Most localization approaches build a map between the signal space and the physical location space in a offline phase, and then using the received-signal-strength (RSS) map to estimate the location in an online phase. However, the map can be outdated when the signal-strength values change with time due to environmental dynamics. It is infeasible or expensive to repeat data calibration for reconstructing the RSS map. In such a case, it is important to adapt the model learnt in one time period to another time period without too much recalibration. In this paper, we present a location-estimation approach based on Manifold co-Regularization, which is a machine learning technique for building a mapping function between data. We describe LeManCoR, a system for adapting the mapping function between the signal space and physical location space over different time periods based on Manifold Co-Regularization. We show that LeManCoR can effectively transfer the knowledge between two time periods without requiring too much new calibration effort. We illustrate LeMan-CoR's effectiveness in a real 802.11 WiFi environment.\", 'This study is focused on querying accomplished on structured spaces of information. Querying is understood in terms of mining structures of information and of knowledge understanding. We consider information as a subject of descriptions expressed in some language. Information is hidden behind such descriptions. Operations done on structured spaces of information are performed on language constructions describing such structures. However, automatic operations not always can be performed directly on language constructions. In such cases it is necessary to expand performance to the space of information. The study concerns paginated (i.e. printed and handwritten) music notation. It is shown that querying in the space of music information requires syntactic structuring as well as its expansion to semantic analysis. It is worth underlining that data understanding requires analysis of uncertainty: analyzed data are usually incomplete, uncertain and with some incorrectness. Such imperfectness of information is hidden under the level of syntax and semantics. Due to limitation of the paper this problem is not studied.', 'Agriculture is the dominant sector in the Ethiopian economy but it is characterized by low productivity. Ethiopia is interested in creating access to agricultural knowledge through an agricultural knowledge management system (AKMS). Such a system has been developed using a web-based portal named Ethiopian Agriculture Portal (EAP). It is facilitated through Woreda Knowledge Centers (WKCs) which are in 10 Pilot Learning Woredas (PLW). Providing knowledge in the appropriate format, identification of affordable technological infrastructure, and integrating indigenous agricultural knowledge into the knowledge system is vital to empowering development agents (extension workers) in Ethiopia. This study addresses two research questions: 1)To what extent does the centralized AKMS support WKCs access and utilization of agricultural knowledge? 2) How can the existing AKMS support capturing and sharing of indigenous agricultural knowledge and best practices?', 'It has been widely observed that different NLP applications require different sense granularities in order to best exploit word sense distinctions, and that for many applications WordNet senses are too fine-grained. In contrast to previously proposed automatic methods for sense clustering, we formulate sense merging as a supervised learning problem, exploiting human-labeled sense clusterings as training data. We train a discriminative classifier over a wide variety of features derived from WordNet structure, corpus-based evidence, and evidence from other lexical resources. Our learned similarity measure outperforms previously proposed automatic methods for sense clustering on the task of predicting human sense merging judgments, yielding an absolute F-score improvement of 4.1% on nouns, 13.6% on verbs, and 4.0% on adjectives. Finally, we propose a model for clustering sense taxonomies using the outputs of our classifier, and we make available several automatically sense-clustered WordNets of various sense granularities.', \"Patch management of networks is essential to mitigate the risks from the exploitation of vulnerabilities through malware and other attacks, but by set- ting too rigorous a patching policy for network devices the IT security team can also create burdens for IT operations or disruptions to the business. Different patch deployment timelines could be adopted with the aim of reducing this op- erational cost, but care must be taken not to substantially increase the risk of emergency disruption from potential exploits and attacks. In this paper we ex- plore how the IT security policy choices regarding patching timelines can be made in terms of economically-based decisions, in which the aim is to minimize the expected overall costs to the organization from patching-related activity. We introduce a simple cost function that takes into account costs incurred from dis- ruption caused by planned patching and from expected disruption caused by emergency patching. To explore the outcomes under different patching policies we apply a systems modelling approach and Monte Carlo style simulations. The results from the simulations show disruptions caused for a range of patch dep- loyment timelines. These results together with the cost function are then used to identify the optimal patching timelines under different threat environment con- ditions and taking into account the organization's risk tolerance.\", 'We present a framework for pen-based, multi-user, online collaboration in mathematical domains. This environment provides participants, who may be in the same room or across the planet, with a shared whiteboard and voice channel. The digital ink stream is transmitted as InkML, allowing special recognizers for different content types, such as mathematics and diagrams. Sessions may be recorded and stored for later playback, analysis or annotation. The framework is currently structured to use the popular Skype and Google Talk services for the communications channel, but other transport mechanisms could be used. The goal of the work is to support computer-enhanced distance collaboration, where domain-specific recognizers handle different kinds of digital ink input and editing. The first of these recognizers is for mathematics, which allows converting math input into machine-understandable format. This supports multi-party collaboration, with sessions recorded in rich formats that allow semantic analysis and manipulation of the content.', \"Nous considerons dans cet article des reseaux de Petri etiquetes sans λ. On les appelle normalises si leurs arcs ne sont pas values et si leurs marquages initiaux et finals sont des sous-ensembles de l'ensemble des places. Nous prouvons que tout reseau de Petri general peut etre (effectivement) transforme en un reseau de Petri normalise ayant exactement le meme comportement concurrent. Ses comportements sequentiels finis et infinis ainsi que ses suites de pas sont egalement preserves. Ceci permet de toujours considerer des reseaux de Petri sous une forme normalisee quand on travaille sur le comportement des reseaux, sans restreindre la generalite des resultats. Ainsi un bon nombre de recherches futures devrait se trouver facilite\", \"The last few years have seen an explosion in the amount of text becoming available on the World Wide Web as online communities of users in diverse domains emerge to share documents and other digital resources. In this paper we explore the issue of how to provide a low-level information extraction tool based on hidden Markov models that can identify and classify terminology based on previously marked-up examples. Such a tool should provide the basis for a domain portable information extraction system, that when combined with search technology can help users to access information more effectively within their document collections than today's information retrieval engines alone. We present results of applying the model in two diverse domains: news and molecular biology and discuss the model and term markup issues that this investigation reveals.\", 'The Self-organizing map (SOM) has been widely used in financial applications, not least for time-series analysis. The SOM has not only been utilized as a stand-alone clustering technique, its output has also been used as input for second-stage clustering. However, one ambiguity with the SOM clustering is that the degree of membership in a particular cluster is not always easy to judge. To this end, we propose a fuzzy C-means clustering of the units of two previously presented SOM models for financial time-series analysis: financial benchmarking of companies and monitoring indicators of currency crises. It allows each time-series point to have a partial membership in all identified, but overlapping, clusters, where the cluster centers express the representative financial states for the companies and countries, while the fluctuations of the membership degrees represent their variations over time.', 'In previous works a novel flexible and versatile handling concept, called PARAGRIP(Parallel Gripping), was introduced. This concept is based ona reconfigurable architecture with a modular and alterable layout. The robot system is able to handle objects with six DOF by forming a parallel kinematic structure including several robotic arms and the object itself. As many kinematic parameters, like the grasp- and base-points of the arms as well as the arm combination can be designed freely, the handling system offers a fast and economic possibility to adapt the performances to the requirements of the task. This adaption can proceed before or even during manipulation. The latter is realized by dynamic re-grasping, where the object is passed from one arm to the next, if more than three arms are available in the layout.#R##N##R##N#This Paper deals with the question how an optimal configuration set can be planned automatically, if the robot layout offers the possibility of dynamic re-grasping. It shows the benefits and the challenges as well as the strategies of the planning process and the realization. The focus of this paper is how to manage the complexity of this numerousness of configuration possibilities and choose the optimal one within the shortest computation time.', \"Business processes are recognized by organizations as one of the most important intangible assets, since they let organizations improve their competitiveness. Business processes are supported by enterprise information systems, which can evolve over time and embed particular business rules that are not present anywhere else. Thus, there are many organizations with inaccurate business processes, which prevent the modernization of enterprise information systems in line with the business processes that they support. Therefore, business process mining techniques are often used to retrieve reliable business processes from the event logs recorded during the execution of enterprise systems. Unfortunately, such event logs are represented with purpose-specific notations such as Mining XML and still don't apply the recent software modernization standard: ISO 19506 (KDM, Knowledge Discovery Metamodel). This paper presents an exogenous model transformation between these two notations. The main advantage is that process mining techniques can be effectively reused within software modernization projects according to the standard notation. This paper is particularly focused on the empirical evaluation of this transformation by simulating different kinds of business process models and several event logs with different sizes and configurations from such models. After analyzing all the model transformation executions, the study demonstrates that the transformation can provide suitable KDM models in a linear time in accordance with the size of the input models.\", 'This paper presents an evolutionary Multiobjective learning model achieving positive synergy between the Inference System and the Rule Base in order to obtain simpler and still accurate linguistic fuzzy models by learning fuzzy inference operators and applying rule selection. The Fuzzy Rule Based Systems obtained in this way, have a better trade-off between interpretability and accuracy in linguistic fuzzy modeling applications.', 'In the domain of ontology design as well as in Knowledge Representation, modeling universals is a challenging problem. Most approaches that have addressed this problem rely on Description Logics (DLs) but many difficulties remain , due to under-constrained representation which reduces the inferences that can be drawn and further causes problems in expressiveness. In mathematical logic and program checking, type theories have proved to be appealing but, so far they have not been applied in the formalization of ontologies. To bridge this gap, we present in this paper a theory for representing ontologies in a de pendently- typed framework which relies on strong formal foundations including both a constructive logic and a functional type system. The language of this theory defines in a precise way what ontol ogical primitives such as classes, relations, properties, etc., and thereof roles, are. The first part of the paper details how the se primitives are defined and used within the theory. In a seco nd part, we focus on the formalization of the role primitive. A review of significant role properties leads to the specificati on of a role profile and most of the remaining work details through nu merous examples, how the proposed theory is able to fully satisfy this profile. It is demonstrated that dependent types can mod el several non-trivial aspects of roles including a formal s olution for generalization hierarchies, identity criteria for roles a nd other contributions. A discussion is given on how the theory is able to cope with many of the constraints inherent in a good role representation.', 'This paper proposes an efficient two stage demosaicing method to interpolate color filter array images. The proposed method based on the edge sensing technique improves the interpolation performance by adopting the color difference model for a green channel as well as a red/blue channel. In particular, the green channel interpolation method with a new concept includes the gradient operator, which uses the total amount of slope changes in adjacent color information, and the missing green color estimation, which uses Approximated Directional Line Averages. Comparing with various comparative experiments between the conventional results and the proposed ones, the performances of the proposed method in this paper outperform to existing algorithms in terms of visual performance both in numerical and visual aspects. Our method of demosaicing improves the standard performance by8.927dB on the average in comparison of other methods in MSE(Mean square Error).', 'Ubiquitous computing has led to an ever-increasing cascade of information about us, our friends, our societies, and the planet. Lima and others view this \"new data\" as an opportunity for individuals to develop network thinking; once people understand the whole, they can better control their contribution to global social issues like climate change. However, at present, such data is difficult to interpret by anyone, let alone by non-specialist users.#R##N##R##N#I believe that a variety of issues stand in the way of individuals understanding complex data sets. I will begin by discussing cognitive style (deductive and inductive logic). Then, after considering existing graphic principles for dealing with \"visual complexity,\" I suggest interfaces need to provide indications of place, date, validity, probability, and privacy. Finally, I briefly discuss some of the boundaries that exist between my networks of data and yours due to the hidden algorithms of search engines and the challenge of creating common ground when visualizations are increasingly personalized.', 'Action research is used to gain understanding of how an IS development methodology emerges in practice and how it can contribute to value creation in organizations. The Multiview framework is used to guide the action research project. A graphical notation for mapping the unfolding of IS development projects is developed and applied to the project. Reflection on the project leads to a number of lessons being drawn about the organization of the IS development process, addressing themes such as vision, time pacing, and the role of architecture. The paper concludes with ideas about how the theoretical underpinnings of IS development might be bolstered by complex adaptive systems.', 'Air pollution in big cities is a major health problem. Pollutants in the air may have severe consequences in humans, creating conditions for several illness and also affect tissues and organs, and also affect other animals and crop productivity. From several years now, the air quality has been monitored by stations distributed over major cities, and the concentration of several pollutants is measured. From these data sets, and applying the data visualization capabilities of the self-organized map, we analyzed the air quality in Mexico City. We were able to detect some hidden patterns regarding the pollutant concentration, as well as to study the evolution of air quality from 2003 to 2010.', 'The syntactic complexity of a regular language is the cardinality of its syntactic semigroup. The syntactic complexity of a subclass of the class of regular languages is the maximal syntactic complexity of languages in that class, taken as a function of the state complexity n of these languages. We study the syntactic complexity of prefix-, suffix-, and bifix-free regular languages. We prove that nn-2 is a tight upper bound for prefix-free regular languages. We present properties of the syntactic semigroups of suffix- and bifix-free regular languages, and conjecture tight upper bounds on their size.', 'Environments with frequent changes in application requirements demand an evolutionary approach for database modeling. The challenge is greater when the database must support multiple applications simultaneously. An existing solution for database evolution is refactoring with a transition period. During this period, both the old and the new database schemas coexist and data is replicated in a synchronous process. This solution brings several difficulties, such as interference with the operation of applications. To minimize these difficulties, in this paper we present an asynchronous approach to keep these schemas updated. This paper presents the design for an experimental assessment of this novel approach for evolutionary database development.', 'Game theory is concerned with optimization problems involving several players with conflicting interests. Differential games are an interesting area inside this field in which the problem is formulated by means of dynamical systems. In spite that the theoretical solution of differential games is well known, faced with large-scale, complex systems, analytical or, even, numerical methods are not usually suitable. Genetic algorithms appear to be useful for solving such problems when dealing with nonlinear, large-scale systems. This paper shows how co-evolutionary algorithms can be applied to solve differential games and presents a computer tool to formulate and solve these problems. The differential equations which define the system under study are written in Vensim, a visual modeling tool. The usefulness of the presented tool is shown by means of two examples.', 'A significant shortcoming of traditional modeling methodologies is the limited access they provide for decision-makers who are not modeling specialists. This paper presents an expert system approach to address this shortcoming. An expert system called the experimental frame expert system (EFES) was developed for this purpose within an advanced modeling environment for manufacturing systems. EFES reduces the dependence upon modeling specialists, and thus, makes models, both analytical and simulation, more accessible to decision-makers. This is accomplished by using two knowledge bases, one related to the manufacturing system specific symptoms and problems, and the other to system analysis and optimization tools. This paper presents the dissertation research effort that led to development of these two knowledge bases as well as the EFES framework within the advanced modeling environment.', 'In this paper we present an original semi-supervised method for the segmentation of in situ tree color images which combines color quantization, adaptive fragmentation of learning areas defined by the human operator and labeling propagation. A mathematical morphology post-processing is introduced to emphasize the narrow and thin structures which characterize branches. Applied in the L*a*b* color system, this method is well adapted to easily adjust the learning set so that the resultant labeling corresponds to the accuracy achieved by the human operator. The method has been embarked and evaluated on a tablet to help tree professionals in their expertise or diagnosis. The images, acquired and processed with a mobile device, present more or less complex background both in terms of content and lightness, more or less dense foliage and more or less thick branches. Results are good on images with soft lightness without direct sunlight.', 'The morphological changes of the vertebrae associated with normal aging are still subject of debate, whereas this knowledge is important in detecting vertebral fractures and degenerative shape changes. The aim of this study is to present a method to statistically analyze the vertebral shape and determining the morphometric changes related to normal aging. The analysis is performed on the L2 lumbar vertebrae from a large dataset of Computed Tomography scans. The surface meshes of all vertebrae, with a groupwise vertex correspondence between them, are first acquired by an intensity based registration process onto a segmented reference. Principal component analysis then reduces the dimensionality to the main modes of variation which were subsequently analyzed by multiple linear regression to acquire the global shape variations with respect to the age of the subjects. In addition, the correlation with age of the deformation at each mesh vertex is analyzed, giving a significance map of the age related changes. This analysis shows several shape changes which are in agreement with previous studies while also giving a more detailed global shape analysis. Understanding the normal shape changes allows for a better diagnosis of vertebral fractures and spinal pathologies.', 'Automated system deployment frameworks and configuration management systems have been in wide use for a number of years. However, due to increasing pressures to maintain high availability, coupled with the price effects of commodity servers, administrators may be required to deploy large numbers of systems in shorter time frames than is normally possible with available staff. In this paper, we describe a straightforward procedure using commonly-available infrastructure to enable rapid simultaneous deployment of hundreds of machines by temporary staff. As an example of the efficacy of this approach, we present a case study in rapid systems deployment at Purdue University. On May 5th, we deployed Purdue\\'s \"Steele\" cluster, installing over 500 compute nodes in a single business day.', 'We study the role of help in Non-Interactive Zero-Knowledge protocols and its relation to the standard interactive model. In the classical case, we show that help and interaction are equivalent, answering an open question of Ben-Or and Gutfreund. This implies a new complete problem for the class SZK, the Image Intersection Density. For this problem, we also prove a polarization lemma which is stronger than the previously known one. #R##N#In the quantum setting, we define the notion of quantum help and show in a more direct way that help and interaction are again equivalent. Moreover, we define quantum Non-Interactive Zero-Knowledge with classical help and prove that it is equal to the class of languages that have classical honest-Verifier Zero Knowledge protocols secure against quantum Verifiers. Last, we provide new complete problems for all these quantum classes. #R##N#Similar results were independently discovered by Dragos Florin Ciocan and Salil Vadhan.', 'Multiple datasets that add high value to biomedical research have been exposed on the web as a part of the Life Sciences Linked Open Data (LSLOD) Cloud. The ability to easily navigate through these datasets is crucial for personalized medicine and the improvement of drug discovery process. However, navigating these multiple datasets is not trivial as most of these are only available as isolated SPARQL endpoints with very little vocabulary reuse. The content that is indexed through these endpoints is scarce, making the indexed dataset opaque for users. In this paper, we propose an approach for the creation of an active Linked Life Sciences Data Roadmap, a set of congurable rules which can be used to discover links (roads) between biological entities (cities) in the LSLOD cloud. We have catalogued and linked concepts and properties from 137 public SPARQL endpoints. Our Roadmap is primarily used to dynamically assemble queries retrieving data from multiple SPARQL endpoints simultaneously. We also demonstrate its use in conjunction with other tools for selective SPARQL querying, semantic annotation of experimental datasets and the visualization of the LSLOD cloud. We have evaluated the performance of our approach in terms of the time taken and entity capture. Our approach, if generalized to encompass other domains, can be used for road-mapping the entire LOD cloud.']\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "universal-sentence-encoder is not available.\n\nTry: pip install top2vec[sentence_encoders]\n\nAlternatively try: pip install tensorflow tensorflow_hub tensorflow_text",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/yp/n2pvc9c13zq1_qk31djqb5d40000gn/T/ipykernel_89740/1860085855.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mabstract_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mabstract_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTop2Vec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mabstract_list\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0membedding_model\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'universal-sentence-encoder'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtokenizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbigrammer\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mspeed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"deep-learn\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Topic-model-dblp-ref-0\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/PhD/InfluenceGraph/venv/lib/python3.9/site-packages/top2vec/Top2Vec.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, documents, min_count, embedding_model, embedding_model_path, speed, use_corpus_file, document_ids, keep_documents, workers, tokenizer, use_embedding_model_tokenizer, umap_args, hdbscan_args, verbose)\u001B[0m\n\u001B[1;32m    310\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0membedding_model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 312\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_import_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    313\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    314\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Pre-processing documents for training'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/PhD/InfluenceGraph/venv/lib/python3.9/site-packages/top2vec/Top2Vec.py\u001B[0m in \u001B[0;36m_check_import_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    822\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_model\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m'distiluse-base-multilingual-cased'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    823\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_HAVE_TENSORFLOW\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 824\u001B[0;31m                 raise ImportError(f\"{self.embedding_model} is not available.\\n\\n\"\n\u001B[0m\u001B[1;32m    825\u001B[0m                                   \u001B[0;34m\"Try: pip install top2vec[sentence_encoders]\\n\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    826\u001B[0m                                   \"Alternatively try: pip install tensorflow tensorflow_hub tensorflow_text\")\n",
      "\u001B[0;31mImportError\u001B[0m: universal-sentence-encoder is not available.\n\nTry: pip install top2vec[sentence_encoders]\n\nAlternatively try: pip install tensorflow tensorflow_hub tensorflow_text"
     ]
    }
   ],
   "source": [
    "from top2vec import Top2Vec\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "\n",
    "def bigrammer(doc):\n",
    "    sentence_stream = simple_preprocess(strip_tags(doc), deacc=True)\n",
    "    return bigram_phraser[sentence_stream]\n",
    "\n",
    "sentence_stream = [doc.split(\" \") for doc in  abstract_list]\n",
    "bigram = Phrases(sentence_stream, min_count=5, threshold=100, delimiter=b' ')\n",
    "bigram_phraser = Phraser(bigram)\n",
    "\n",
    "\n",
    "model = Top2Vec(abstract_list,embedding_model='universal-sentence-encoder',tokenizer=bigrammer,speed=\"deep-learn\")\n",
    "model.save(\"Topic-model-dblp-ref-0\")\n",
    "\n",
    "print(model.get_num_topics())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model.get_topics())\n",
    "print(len(abstract_list))\n",
    "print(abstract_list[9])\n",
    "print(abstract_list[19])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make the raw citation network by networkx\n",
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for i in range(count):\n",
    "    G.add_node(doc_list[i],citation=citation_list[i],keywords=abstract_list[i])\n",
    "    for j in range(len(ref_list[i])):\n",
    "        G.add_node(ref_list[i][j])\n",
    "        G.add_edge(ref_list[i][j],doc_list[i])\n",
    "print(nx.info(G))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def graph_cleaner(graph,attribute):\n",
    "    r=nx.DiGraph.to_undirected(graph)\n",
    "    node_list=[]\n",
    "    v= nx.get_node_attributes(r,attribute)\n",
    "    for node in r.nodes:\n",
    "        if node not in v:\n",
    "            node_list.append(node)\n",
    "    graph.remove_nodes_from(node_list)\n",
    "\n",
    "T=G.copy()\n",
    "print(\"before graph processing:\",nx.info(T))\n",
    "remove = [node for node, degree in dict(T.degree()).items() if degree ==0]\n",
    "T.remove_nodes_from(remove)\n",
    "graph_cleaner(T,\"keywords\")\n",
    "remove = [node for node, degree in dict(T.degree()).items() if degree ==0]\n",
    "T.remove_nodes_from(remove)\n",
    "print(\"after graph processing:\",nx.info(T))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#functions for calculating the impact influenced by https://link.springer.com/content/pdf/10.1007/s11192-021-04063-1.pdf\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(set(list1)) + len(set(list2))) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "## p2 cited p1, and p1 influenced p2\n",
    "def paper_citation_relation(g,p1,p2,f1,f2,c1,c2):\n",
    "    if g.has_edge(p1,p2) and (c1+c2)!=0:\n",
    "       return (c1/(c1+c2))+jaccard_similarity(f1, f2)\n",
    "    else: return 0\n",
    "#f1 is the list of keywords of paper p1\n",
    "def keyword_citation_relation_raw(fi,fj,f1,f2):\n",
    "    # if order is important\n",
    "    #return 1/((f1.index(fi)+1)*(1+f2.index(fj)))\n",
    "    #if not\n",
    "    return 1\n",
    "def keyword_citation_relation_pre(g,p1,p2,f1,f2,c1,c2,fi,fj):\n",
    "    w_pp=paper_citation_relation(g,p1,p2,f1,f2,c1,c2)\n",
    "    w_ca_raw=keyword_citation_relation_raw(fi,fj,f1,f2)\n",
    "    sum=0\n",
    "    for i in f1:\n",
    "        for j in f2:\n",
    "            sum=sum+keyword_citation_relation_raw(i,j,f1,f2)\n",
    "    return w_pp* w_ca_raw/sum\n",
    "\n",
    "def keyword_citation_relation(g,fi,fj):\n",
    "    influence=0\n",
    "    k=nx.get_node_attributes(g,\"keywords\")\n",
    "    c=nx.get_node_attributes(g,\"citation\")\n",
    "    if fi != fj:\n",
    "        for node in g.nodes:\n",
    "            if fi in k[node]:\n",
    "                c1=c[node]\n",
    "                f1=k[node]\n",
    "                for neighbor in g.neighbors(node):\n",
    "                    if fj in k[neighbor]:\n",
    "                        c2=c[neighbor]\n",
    "                        f2=k[neighbor]\n",
    "                        influence=influence+keyword_citation_relation_pre(g,node,neighbor,f1,f2,c1,c2,fi,fj)\n",
    "        return influence\n",
    "    else: return 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#Test the result\n",
    "print(keyword_citation_relation(T,\"Machine learning\",\"Computer vision\"))\n",
    "print(keyword_citation_relation(T,\"Computer vision\",\"Machine learning\"))\n",
    "\n",
    "print(keyword_citation_relation(T,\"Machine learning\",\"Reinforcement learning\"))\n",
    "print(keyword_citation_relation(T,\"Reinforcement learning\",\"Machine learning\"))\n",
    "\n",
    "print(keyword_citation_relation(T,\"Reinforcement learning\",\"Computer vision\"))\n",
    "print(keyword_citation_relation(T,\"Computer vision\",\"Reinforcement learning\"))\n",
    "\n",
    "print(keyword_citation_relation(T,\"Machine learning\",\"Machine learning\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}